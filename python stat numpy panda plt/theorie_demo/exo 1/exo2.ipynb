{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing CSV File from CSV via pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file imported successfully\n",
      "=====================================\n",
      "   index  math  eng group gender  count\n",
      "0      0   2.0  6.0  lang      F      1\n",
      "1      1   3.0  6.0  lang      F      1\n",
      "2      2   3.0  7.0  lang      F      2\n",
      "3      3   3.0  7.0  lang      M      2\n",
      "4      4   3.0  8.0  lang      F      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"gb_notes_v2.csv\")\n",
    "print(\"CSV file imported successfully\")\n",
    "print(\"=====================================\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 'Qualitative nominale', 'math': 'Quantitative continue', 'eng': 'Quantitative continue', 'group': 'Qualitative nominale', 'gender': 'Qualitative nominale', 'count': 'Quantitative discrète'}\n"
     ]
    }
   ],
   "source": [
    "def determine_variable_type(df):\n",
    "    variable_types = {}\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"object\" or df[column].name == \"index\":\n",
    "            variable_types[column] = \"Qualitative nominale\"\n",
    "        else:\n",
    "            if df[column].name == \"eng\" or df[column].name == \"math\":\n",
    "                variable_types[column] = \"Quantitative continue\"\n",
    "            else:\n",
    "                variable_types[column] = \"Quantitative discrète\"\n",
    "    return variable_types\n",
    "\n",
    "\n",
    "variable_types = determine_variable_type(df)\n",
    "print(variable_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the mean, median, mode, and standard deviation for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math - Moyenne pondérée: 6.536\n",
      "eng - Moyenne pondérée: 6.672\n",
      "=====================================\n",
      "Average of each column\n",
      "{'math': 6.536, 'eng': 6.672}\n"
     ]
    }
   ],
   "source": [
    "def average_calculation(df):\n",
    "    averages = {}\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"object\" or column == \"index\" or column == \"count\":\n",
    "            continue\n",
    "        else:\n",
    "            weighted_sum = sum(df[column] * df[\"count\"])\n",
    "            total_count = df[\"count\"].sum()\n",
    "            column_avg = weighted_sum / total_count\n",
    "            averages[column] = column_avg\n",
    "            print(f\"{column} - Moyenne pondérée: {column_avg}\")\n",
    "    return averages\n",
    "\n",
    "\n",
    "averages = average_calculation(df)\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"Average of each column\")\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math - Médiane pondérée: 6.0\n",
      "eng - Médiane pondérée: 7.0\n",
      "=====================================\n",
      "Médiane de chaque colonne\n",
      "{'math': 6.0, 'eng': 7.0}\n"
     ]
    }
   ],
   "source": [
    "def median_calculation(df):\n",
    "    medians = {}\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"object\" or column == \"index\" or column == \"count\":\n",
    "            continue\n",
    "        else:\n",
    "            # Trier les données par la colonne d'intérêt\n",
    "            df_sorted = df.sort_values(by=column)\n",
    "            total_count = df_sorted[\"count\"].sum()\n",
    "            median_index = total_count / 2\n",
    "            cumulative_sum = 0\n",
    "            median = 0\n",
    "            for index, row in df_sorted.iterrows():\n",
    "                cumulative_sum += row[\"count\"]\n",
    "                if cumulative_sum >= median_index:\n",
    "                    median = row[column]\n",
    "                    break\n",
    "            medians[column] = median\n",
    "            print(f\"{column} - Médiane pondérée: {median}\")\n",
    "    return medians\n",
    "\n",
    "\n",
    "medians = median_calculation(df)\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"Médiane de chaque colonne\")\n",
    "print(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group - Mode: science\n",
      "gender - Mode: F\n",
      "=====================================\n",
      "Mode of each column\n",
      "{'group': 'science', 'gender': 'F'}\n"
     ]
    }
   ],
   "source": [
    "def mode_calculation(df):\n",
    "    modes = {}\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"object\":\n",
    "            mode = df[column].mode().values[0]\n",
    "            modes[column] = mode\n",
    "            print(f\"{column} - Mode: {mode}\")\n",
    "    return modes\n",
    "\n",
    "\n",
    "modes = mode_calculation(df)\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"Mode of each column\")\n",
    "print(modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispersion methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math - Amplitude: 8.0\n",
      "eng - Amplitude: 9.0\n",
      "=====================================\n",
      "Amplitudes of each column\n",
      "{'math': 8.0, 'eng': 9.0}\n"
     ]
    }
   ],
   "source": [
    "def amplitudes_calculation(df):\n",
    "    amplitudes = {}\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"object\" or column == \"index\" or column == \"count\":\n",
    "            continue\n",
    "        else:\n",
    "            min_value = df[column].min()\n",
    "            max_value = df[column].max()\n",
    "            amplitude = max_value - min_value\n",
    "            amplitudes[column] = amplitude\n",
    "            print(f\"{column} - Amplitude: {amplitude}\")\n",
    "    return amplitudes\n",
    "\n",
    "\n",
    "amplitudes = amplitudes_calculation(df)\n",
    "print(\"=====================================\")\n",
    "print(\"Amplitudes of each column\")\n",
    "print(amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math - Déviation absolue moyenne pondérée: 1.262224\n",
      "eng - Déviation absolue moyenne pondérée: 1.307456\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "def calculate_weighted_mean(df, column):\n",
    "    weighted_sum = sum(df[column] * df[\"count\"])\n",
    "    total_count = df[\"count\"].sum()\n",
    "    return weighted_sum / total_count\n",
    "\n",
    "\n",
    "def calculate_weighted_mad(df, column):\n",
    "    mean = calculate_weighted_mean(df, column)\n",
    "    absolute_deviations = abs(df[column] - mean)\n",
    "    weighted_absolute_deviations = absolute_deviations * df[\"count\"]\n",
    "    mad = weighted_absolute_deviations.sum() / df[\"count\"].sum()\n",
    "    return mad\n",
    "\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype != \"object\" and column != \"index\" and column != \"count\":\n",
    "        mad = calculate_weighted_mad(df, column)\n",
    "        print(f\"{column} - Déviation absolue moyenne pondérée: {mad}\")\n",
    "\n",
    "print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math - Variance: 2.3007039999999996\n",
      "eng - Variance: 2.480416\n",
      "=====================================\n",
      "Variance of each column\n",
      "{'math': 2.3007039999999996, 'eng': 2.480416} \n",
      "\n",
      "math - Écart-type: 1.51680717297882\n",
      "eng - Écart-type: 1.5749336493960626\n",
      "=====================================\n",
      "std of each column\n",
      "{'math': 1.51680717297882, 'eng': 1.5749336493960626}\n"
     ]
    }
   ],
   "source": [
    "def variances(df):\n",
    "    variances = {}\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == \"object\" or column == \"index\" or column == \"count\":\n",
    "            continue\n",
    "        else:\n",
    "            mean = calculate_weighted_mean(df, column)\n",
    "            squared_deviations = (df[column] - mean) ** 2\n",
    "            weighted_squared_deviations = squared_deviations * df[\"count\"]\n",
    "            variance = weighted_squared_deviations.sum() / df[\"count\"].sum()\n",
    "            variances[column] = variance\n",
    "            print(f\"{column} - Variance: {variance}\")\n",
    "    return variances\n",
    "\n",
    "\n",
    "def standard_deviations(variances):\n",
    "    std_devs = {}\n",
    "    for column, variance in variances.items():\n",
    "        std_dev = variance**0.5\n",
    "        std_devs[column] = std_dev\n",
    "        print(f\"{column} - Écart-type: {std_dev}\")\n",
    "    return std_devs\n",
    "\n",
    "\n",
    "variances = variances(df)\n",
    "print(\"=====================================\")\n",
    "print(\"Variance of each column\")\n",
    "print(variances, \"\\n\")\n",
    "\n",
    "std_devs = standard_deviations(variances)\n",
    "print(\"=====================================\")\n",
    "print(\"std of each column\")\n",
    "print(std_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math - Q1: 5.0, Q3: 8.0, IQR: 3.0\n",
      "eng - Q1: 6.0, Q3: 8.0, IQR: 2.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_weighted_quantile(df, column, quantile):\n",
    "    df_sorted = df.sort_values(by=column)\n",
    "    total_count = df_sorted[\"count\"].sum()\n",
    "    quantile_index = total_count * quantile\n",
    "    cumulative_sum = 0\n",
    "    for index, row in df_sorted.iterrows():\n",
    "        cumulative_sum += row[\"count\"]\n",
    "        if cumulative_sum >= quantile_index:\n",
    "            return row[column]\n",
    "\n",
    "\n",
    "def calculate_weighted_iqr(df, column):\n",
    "    Q1 = calculate_weighted_quantile(df, column, 0.25)\n",
    "    Q3 = calculate_weighted_quantile(df, column, 0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return Q1, Q3, IQR\n",
    "\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype != \"object\" and column != \"index\" and column != \"count\":\n",
    "        Q1, Q3, IQR = calculate_weighted_iqr(df, column)\n",
    "        print(f\"{column} - Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Graphics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. afficher un graphique univarié pour chaque colonne (hors \"index\") du dataset \"notes_v2.csv\", avec:\n",
    "    - un titre\n",
    "    - les labels des axes\n",
    "    - la moyenne et la mediane (si applicable) en \"red\" et \"purple\"\n",
    "    - les valeurs/hauteurs des bar-plots en chiffre\n",
    " \n",
    "2. graphiques bivarié:\n",
    "    - afficher un graphique en nuage de points pour les colonnes \"math\",\"eng\"\n",
    "    - afficher un histogramme (multi-couche superposé) des scores en \"math\" ventilé par \"gender\"\n",
    "        - une couleur par \"gender\"\n",
    "        - alpha de 0.5\n",
    " \n",
    "3. sauver toutes les images dans 2 pdf\n",
    "    - 1: univarié\n",
    "    - 2: bivarié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"notes_v2.csv\")\n",
    "\n",
    "\n",
    "# Étape 1 : Graphiques Univariés\n",
    "def plot_univariate(df):\n",
    "    with PdfPages(\"notes/univariate_plots.pdf\") as pdf:\n",
    "        for column in df.columns:\n",
    "            if column != \"index\" and df[column].dtype != \"object\":\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.histplot(df, x=column, kde=False, color=\"blue\")\n",
    "                mean = df[column].mean()\n",
    "                median = df[column].median()\n",
    "                plt.axvline(mean, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "                plt.axvline(median, color=\"purple\", linestyle=\"dashed\", linewidth=1)\n",
    "                plt.title(f\"Distribution de {column}\")\n",
    "                plt.xlabel(column)\n",
    "                plt.ylabel(\"Fréquence\")\n",
    "                plt.legend({\"Moyenne\": mean, \"Médiane\": median})\n",
    "                for p in plt.gca().patches:\n",
    "                    plt.gca().annotate(\n",
    "                        f\"{p.get_height():.0f}\",\n",
    "                        (p.get_x() + p.get_width() / 2.0, p.get_height()),\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        xytext=(0, 10),\n",
    "                        textcoords=\"offset points\",\n",
    "                    )\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "plot_univariate(df)\n",
    "\n",
    "\n",
    "# Étape 2 : Graphiques Bivariés\n",
    "def plot_bivariate(df):\n",
    "    with PdfPages(\"notes/bivariate_plots.pdf\") as pdf:\n",
    "        # Nuage de points pour \"math\" et \"eng\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(data=df, x=\"math\", y=\"eng\", hue=\"gender\")\n",
    "        plt.title(\"Nuage de points des scores en math et eng\")\n",
    "        plt.xlabel(\"Math\")\n",
    "        plt.ylabel(\"Eng\")\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        # Histogramme des scores en \"math\" ventilé par \"gender\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(\n",
    "            data=df,\n",
    "            x=\"math\",\n",
    "            hue=\"gender\",\n",
    "            multiple=\"stack\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        plt.title(\"Histogramme des scores en math ventilé par gender\")\n",
    "        plt.xlabel(\"Math\")\n",
    "        plt.ylabel(\"Fréquence\")\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "plot_bivariate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des différents graphiques dans le dossier /Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def diagnostiquer_colonnes(df):\n",
    "    diagnostics = {}\n",
    "    for col in df.columns:\n",
    "        if col == \"count\":\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if df[col].nunique() < 20:\n",
    "                type_col = \"Quantitative Discrète\"\n",
    "            else:\n",
    "                type_col = \"Quantitative Continue\"\n",
    "            moyenne = df[col].mean()\n",
    "            mediane = df[col].median()\n",
    "            ecart_type = df[col].std()\n",
    "            etendue = df[col].max() - df[col].min()\n",
    "            diagnostics[col] = {\n",
    "                \"Type\": type_col,\n",
    "                \"Moyenne\": moyenne,\n",
    "                \"Médiane\": mediane,\n",
    "                \"Écart-type\": ecart_type,\n",
    "                \"Étendue\": etendue,\n",
    "            }\n",
    "        else:\n",
    "            if df[col].nunique() < 20:\n",
    "                type_col = \"Qualitative Nominale\"\n",
    "            else:\n",
    "                type_col = \"Qualitative Ordinale\"\n",
    "            mode = df[col].mode()[0]\n",
    "            effectifs = df[col].value_counts()\n",
    "            frequences = df[col].value_counts(normalize=True)\n",
    "            diagnostics[col] = {\n",
    "                \"Type\": type_col,\n",
    "                \"Mode\": mode,\n",
    "                \"Effectifs\": effectifs,\n",
    "                \"Fréquences\": frequences,\n",
    "            }\n",
    "    return diagnostics\n",
    "\n",
    "\n",
    "def calculer_correls(df):\n",
    "    df_numerique = df.select_dtypes(include=[\"number\"])\n",
    "    correlations = df_numerique.corr(method=\"pearson\")\n",
    "    return correlations\n",
    "\n",
    "\n",
    "def calculer_frequences_conjointes(df, col1, col2):\n",
    "    table_conjointe = pd.crosstab(\n",
    "        df[col1], df[col2], values=df[\"count\"], aggfunc=\"sum\"\n",
    "    ).fillna(0)\n",
    "    frequences_conjointes = table_conjointe / table_conjointe.sum().sum()\n",
    "    return table_conjointe, frequences_conjointes\n",
    "\n",
    "\n",
    "def calculer_frequences_conditionnelles(df, col1, col2):\n",
    "    table_conjointe = pd.crosstab(\n",
    "        df[col1], df[col2], values=df[\"count\"], aggfunc=\"sum\"\n",
    "    ).fillna(0)\n",
    "    frequences_conditionnelles = table_conjointe.div(\n",
    "        table_conjointe.sum(axis=1), axis=0\n",
    "    )\n",
    "    return frequences_conditionnelles\n",
    "\n",
    "\n",
    "def plot_histogram(df, col):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df[col], bins=20, weights=df[\"count\"], alpha=0.7, color=\"blue\")\n",
    "    mean = df[col].mean()\n",
    "    median = df[col].median()\n",
    "    plt.axvline(mean, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "    plt.axvline(median, color=\"purple\", linestyle=\"dashed\", linewidth=1)\n",
    "    plt.text(mean, plt.ylim()[1] * 0.9, f\"Mean: {mean:.2f}\", color=\"red\")\n",
    "    plt.text(median, plt.ylim()[1] * 0.8, f\"Median: {median:.2f}\", color=\"purple\")\n",
    "    plt.title(f\"Histogramme de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "\n",
    "\n",
    "def plot_boxplot(df, col):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(df[col], vert=False)\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.xlabel(col)\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(correlations):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(correlations, cmap=\"coolwarm\", interpolation=\"none\", aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(correlations.columns)), correlations.columns, rotation=90)\n",
    "    plt.yticks(range(len(correlations.columns)), correlations.columns)\n",
    "    plt.title(\"Heatmap des corrélations de Pearson\")\n",
    "\n",
    "\n",
    "def plot_barplot(df, col):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    counts = df.groupby(col)[\"count\"].sum()\n",
    "    plt.bar(counts.index, counts.values, alpha=0.7, color=\"blue\")\n",
    "    for i, v in enumerate(counts.values):\n",
    "        plt.text(i, v + 0.5, str(v), ha=\"center\", va=\"bottom\")\n",
    "    plt.title(f\"Effectifs de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Effectifs\")\n",
    "\n",
    "\n",
    "def plot_frequences_conjointes_heatmap(frequences_conjointes, col1, col2):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(\n",
    "        frequences_conjointes, cmap=\"coolwarm\", interpolation=\"none\", aspect=\"auto\"\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.xticks(\n",
    "        range(len(frequences_conjointes.columns)),\n",
    "        frequences_conjointes.columns,\n",
    "        rotation=90,\n",
    "    )\n",
    "    plt.yticks(range(len(frequences_conjointes.index)), frequences_conjointes.index)\n",
    "    plt.title(f\"Fréquences conjointes entre {col1} et {col2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne: index, Type: Quantitative Continue\n",
      "  Moyenne: 65.5\n",
      "  Médiane: 65.5\n",
      "  Écart-type: 38.24918299781056\n",
      "  Étendue: 131\n",
      "Colonne: math, Type: Quantitative Discrète\n",
      "  Moyenne: 6.545454545454546\n",
      "  Médiane: 7.0\n",
      "  Écart-type: 1.9275568381581714\n",
      "  Étendue: 8.0\n",
      "Colonne: eng, Type: Quantitative Discrète\n",
      "  Moyenne: 6.492424242424242\n",
      "  Médiane: 7.0\n",
      "  Écart-type: 2.0657003031196424\n",
      "  Étendue: 9.0\n",
      "Colonne: group, Type: Qualitative Nominale\n",
      "  Mode: science\n",
      "  Effectifs:\n",
      "group\n",
      "science    74\n",
      "lang       58\n",
      "Name: count, dtype: int64\n",
      "  Fréquences:\n",
      "group\n",
      "science    0.560606\n",
      "lang       0.439394\n",
      "Name: proportion, dtype: float64\n",
      "Colonne: gender, Type: Qualitative Nominale\n",
      "  Mode: F\n",
      "  Effectifs:\n",
      "gender\n",
      "F    66\n",
      "M    66\n",
      "Name: count, dtype: int64\n",
      "  Fréquences:\n",
      "gender\n",
      "F    0.5\n",
      "M    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Corrélations de Pearson:\n",
      "           index      math       eng     count\n",
      "index  1.000000  0.982782  0.047486  0.002194\n",
      "math   0.982782  1.000000 -0.102480 -0.004115\n",
      "eng    0.047486 -0.102480  1.000000  0.072937\n",
      "count  0.002194 -0.004115  0.072937  1.000000\n",
      "\n",
      "Fréquences conjointes entre group et gender:\n",
      " gender       F      M\n",
      "group                \n",
      "lang     0.307  0.193\n",
      "science  0.209  0.291\n",
      "\n",
      "Fréquences conditionnelles de group par rapport à gender:\n",
      " gender       F      M\n",
      "group                \n",
      "lang     0.614  0.386\n",
      "science  0.418  0.582\n"
     ]
    }
   ],
   "source": [
    "# Charger les données depuis un fichier CSV\n",
    "df = pd.read_csv(\"./gb_notes_v2.csv\")\n",
    "\n",
    "# Diagnostiquer les colonnes\n",
    "resultats = diagnostiquer_colonnes(df)\n",
    "\n",
    "# Afficher les résultats\n",
    "for col, details in resultats.items():\n",
    "    print(f\"Colonne: {col}, Type: {details['Type']}\")\n",
    "    if \"Moyenne\" in details:\n",
    "        print(f\"  Moyenne: {details['Moyenne']}\")\n",
    "        print(f\"  Médiane: {details['Médiane']}\")\n",
    "        print(f\"  Écart-type: {details['Écart-type']}\")\n",
    "        print(f\"  Étendue: {details['Étendue']}\")\n",
    "    if \"Mode\" in details:\n",
    "        print(f\"  Mode: {details['Mode']}\")\n",
    "        print(f\"  Effectifs:\\n{details['Effectifs']}\")\n",
    "        print(f\"  Fréquences:\\n{details['Fréquences']}\")\n",
    "\n",
    "# Calculer et afficher les corrélations de Pearson\n",
    "correlations = calculer_correls(df)\n",
    "print(\"\\nCorrélations de Pearson:\\n\", correlations)\n",
    "\n",
    "# Calculer et afficher les fréquences conjointes et conditionnelles pour les colonnes qualitatives\n",
    "colonnes_qualitatives = df.select_dtypes(include=[\"object\"]).columns\n",
    "for i in range(len(colonnes_qualitatives)):\n",
    "    for j in range(i + 1, len(colonnes_qualitatives)):\n",
    "        col1 = colonnes_qualitatives[i]\n",
    "        col2 = colonnes_qualitatives[j]\n",
    "        table_conjointe, frequences_conjointes = calculer_frequences_conjointes(\n",
    "            df, col1, col2\n",
    "        )\n",
    "        frequences_conditionnelles = calculer_frequences_conditionnelles(df, col1, col2)\n",
    "\n",
    "        print(\n",
    "            f\"\\nFréquences conjointes entre {col1} et {col2}:\\n\",\n",
    "            frequences_conjointes,\n",
    "        )\n",
    "        print(\n",
    "            f\"\\nFréquences conditionnelles de {col1} par rapport à {col2}:\\n\",\n",
    "            frequences_conditionnelles,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer les graphiques univariés\n",
    "for col, details in resultats.items():\n",
    "    if \"Moyenne\" in details:\n",
    "        plot_histogram(df, col)\n",
    "        plt.savefig(f\"GB/univariate_{col}_histogram.pdf\")\n",
    "        plt.close()\n",
    "        plot_boxplot(df, col)\n",
    "        plt.savefig(f\"GB/univariate_{col}_boxplot.pdf\")\n",
    "        plt.close()\n",
    "    if \"Mode\" in details:\n",
    "        plot_barplot(df, col)\n",
    "        plt.savefig(f\"GB/univariate_{col}_barplot.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "# Générer les graphiques bivariés\n",
    "# Nuage de points pour \"math\" et \"eng\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = df[\"gender\"].apply(lambda x: {\"M\": \"blue\", \"F\": \"red\"}[x])\n",
    "plt.scatter(df[\"math\"], df[\"eng\"], c=colors, alpha=0.5)\n",
    "plt.title(\"Nuage de points des scores en math et eng\")\n",
    "plt.xlabel(\"Math\")\n",
    "plt.ylabel(\"Eng\")\n",
    "plt.savefig(\"GB/bivariate_math_eng_scatter.pdf\")\n",
    "plt.close()\n",
    "\n",
    "# Histogramme des scores en \"math\" ventilé par \"gender\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "genders = df[\"gender\"].unique()\n",
    "for gender in genders:\n",
    "    subset = df[df[\"gender\"] == gender]\n",
    "    plt.hist(subset[\"math\"], weights=subset[\"count\"], alpha=0.5, label=gender)\n",
    "plt.title(\"Histogramme des scores en math ventilé par gender\")\n",
    "plt.xlabel(\"Math\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.legend()\n",
    "plt.savefig(\"GB/bivariate_math_gender_histogram.pdf\")\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
