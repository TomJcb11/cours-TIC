{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d0eed9-4590-4dcb-8d49-fecadc17f192",
   "metadata": {},
   "source": [
    "# Régression Linéaire et Logistique\n",
    "\n",
    "## Le but de la régression ?\n",
    "Imaginons qu'on ait un ensemble d'observations $\\{ \\forall n : (y_n, x_{n,1}, x_{n,2}, ... , x_{n,K}) \\}$:\n",
    "- ou pour simplifier un tableau avec les colonnes $(y,x_1,x_2,...,x_K)$\n",
    "\n",
    "La régression a pour but de synthétiser et prédire une variable (dépendante) $y$ sur base des variables (indépendantes) $X = (x_1,x_2,..., x_K)$:\n",
    "- $ y \\approx \\hat{y} = f(X) = f(x_1,x_2,...,x_K)$  \n",
    "Il faut noter que souvent, on n'a pas un matching/fitting parfait et il faut se contenter d'une approximation (maitrisée) $\\hat{y}$ de la vraie variable observée $y$.\n",
    "- Alternativement, on exprime cette relation en tenant compte de fluctuation statistique/bruit $\\epsilon$:\n",
    "    - $ y = f(X) + \\epsilon $ \n",
    "\n",
    "La formule exacte de la fonction $f(\\cdot)$ est determiné par 2 choses :\n",
    "- le template de fonction = la catégorie/type de fonction: ceci est imposé par le scientifique/analyste/ingénieur/développeur, car cela dépend du contexte/signification du problème \n",
    "- les paramètres associés à ce template: ceux-ci sont déterminés avec les données.\n",
    "\n",
    "\n",
    "Exemple:\n",
    "- on souhaite prédire le prix d'une maison $y$, en se basant sur la surface habitable $x_1$, le PEB du batiment $x_2$, et la surface du jardin $x_3$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a019501-d2cd-4f50-9724-897f7d8ae89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### EXEMPLE 01\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "\n",
    "\n",
    "N = 10_000                                  ## nombre de points\n",
    "X = np.random.normal(0,1,(N)) + 5           ## X suit une normale\n",
    "Y = 3+2*X + 0.75*np.random.normal(0,1,(N))  ## Y est fortement corrélé avec X\n",
    "                                            ## Y = 3 + 2*X + \\epsilon\n",
    "\n",
    "def y_hat(x, a = 0, b = 1):\n",
    "    ### fonction linéaire\n",
    "    return a+b*x \n",
    "x_theorique = np.linspace(0,10,1001)\n",
    "\n",
    "plt.title(\"linear regression y = a + b*x\")\n",
    "plt.scatter(X,Y)\n",
    "### ici, je sais que les valeurs optimales sont (a=3,b=2), mais je sais le \"decouvrir\" avec les methodes de fitting\n",
    "plt.plot(x_theorique,y_hat(x_theorique,a=3  ,b=2  ), c= 'red',label =\"best fit with a=3, b=2\")\n",
    "plt.plot(x_theorique,y_hat(x_theorique,a=2.9,b=2.1), c=\"green\",label =\"possible fit with a=2.9,b=2.1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53bd7df-d55a-43b8-b345-77cbf42a2846",
   "metadata": {},
   "source": [
    "## la régression linéaire simple\n",
    "- $\\hat{y} = f(X) = a + bx$\n",
    "- le template de la régression est une fonction linéaire (=simple proportion) et ne dépend que d'une seule variable\n",
    "- les paramètres de cette fonction/template sont les coefficients $a,b$\n",
    "- les données sont les paires $\\{(y_n,x_n)\\}$\n",
    "\n",
    "Pour que la régression linéare soit approprié, il faut que:\n",
    "- les coefficients soit (vraiment) constants (sinon pas linéaire)\n",
    "- l'erreur $\\epsilon$ suit une distribution normale centrée à $0$ avec variance $\\sigma^2$: $\\epsilon \\sim N(0,\\sigma^2)$\n",
    "- (la variance de) l'erreur est indépendant des $X$ (= [homoscédasticité](https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98aaaf-3dc4-4506-9d85-572f20adeeca",
   "metadata": {},
   "source": [
    "\n",
    "## fitting et critère de qualité:\n",
    "L'idée c'est qu'il faut déterminer les valeurs de $a$ et $b$, de telle manière que la fonction \"colle\" le mieux aux données $\\{(y_n,x_n)\\}$:\n",
    "- on veut que l'écart global $|y - \\hat{y}|$ est plus petit possible.\n",
    "- c'est un problème d'optimisation\n",
    "- \"[Ajustement de courbe](https://en.wikipedia.org/wiki/Curve_fitting)\" (=EN: fitting)\n",
    "\n",
    "\n",
    "Il existe plusieurs métriques qui quantifient cette proximité à la réalité (=manières de compter les erreurs):\n",
    "- il y a deux **idées de métriques** (toutes les deux applicable aux régressions et classification):\n",
    "    - les **\"fonction de perte\"**, \"fonction de coût\", \"fonction d'erreur\" (EN: loss function, cost function, error function): on souhaite minimiser la fonction de perte \n",
    "    - les **\"scores\"** (EN: scores): on souhaite maximiser le score \n",
    "\n",
    "\n",
    "Dans les problèmes de **régression**:\n",
    "- On veut prédire une valeur qui est plus ou moins proche de la vraie valeur.\n",
    "- Plus on s'éloigne, plus le modèle est mauvais.\n",
    "- Il y a une notion de distance/proximité qui détermine la qualité du modèle.\n",
    "\n",
    "\n",
    "Ceci est à mettre en contraste avec des problèmes de **classification**: \n",
    "- On a soit prédit la bonne catégorie, soit une mauvaise.\n",
    "- Il n'y a pas vraiment de notion de distance.\n",
    "\n",
    "Attention: comme les problèmes de régressions et de classifications sont différents, les scores et/ou fonction pertes qu'on utilise pour les uns n'est pas approprié pour les autres !\n",
    "\n",
    "\n",
    "Ici, il s'agit de régression.\n",
    "Une fonction de coût, parmi les plus importantes dans la régression, c'est l'erreur quadratique moyen (EN: mean square error):  \n",
    "- $ MSE = \\frac{\\sum_n |y_n - \\hat{y}_n|^2}{N}  = \\frac{\\sum_n |y_n - a - b x_n|^2}{N}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49bf336-1377-450f-9ba6-5dffc5aa0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_function(Y_true, Y_pred):\n",
    "    return np.mean((Y_true-Y_pred)*(Y_true - Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9fd6d0-03f8-4ddf-b871-b788a28d7673",
   "metadata": {},
   "source": [
    "### methode force brut:\n",
    "- recherche en grille\n",
    "- EN: brute force, grid search\n",
    "- la methode la plus simple (mais pas le plus efficace), c'est d'évaluer un ensemble de valeurs possibles pour les coefficients $a,b$.\n",
    "\n",
    "pour l'exemple 01:\n",
    "- on essaye toutes les combinaisons imaginable pour\n",
    "    - $a \\in (-5,-4.9,...,4.9,5)$\n",
    "    - $b \\in (-5,-4.9,...,4.9,5)$\n",
    "- pour chaque combinaison, on détermine le \"MSE\"\n",
    "- on prends la combinaison qui nous donne la plus faible valeur du \"MSE\"\n",
    "\n",
    "Le problème de ce genre de recherche de paramètres:\n",
    "- imaginons qu'on veut tester 100 valeurs par paramètre\n",
    "- imaginons qu'on a un nombre de dimension élevé (= beaucoup de colonnes) et/ou un modèle complexe/lourd (= beaucoup de paramètres)\n",
    "    - $M$ nombre de parametres\n",
    "- pour faire une recherche exaustive,il faudra faire $100^M$ evaluations\n",
    "    - exemple: avec un modèle qui a 10 paramètres il y a $100\\,000\\,000\\,000\\,000\\,000\\,000 = 100\\,000\\,000\\text{T}$ (terra) d'evaluations\n",
    "        - c'est beaucoup trop !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2f9006-cd64-4c0d-86f2-3f90094b8529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5499340557261183 (3.0, 2.0)\n"
     ]
    }
   ],
   "source": [
    "lst_a = [x/10 for x in range(-50,51)]\n",
    "lst_b = [x/10 for x in range(-50,51)]\n",
    "\n",
    "dict_mse = {}\n",
    "\n",
    "for a in lst_a:\n",
    "    for b in lst_b:\n",
    "        Y_hat_a_b = y_hat(X,a=a,b=b)\n",
    "        mse = mse_function(Y_true=Y , Y_pred=Y_hat_a_b)\n",
    "        dict_mse[mse] = (a,b) ### potentiellement, on écrase la paire (a,b) existant pour un même mse\n",
    "\n",
    "\n",
    "best_mse = np.min(list(dict_mse.keys()))\n",
    "\n",
    "print(best_mse,dict_mse[best_mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783efd23-2f69-492f-9bbe-4c4169da2122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5499340557261183, [{'a': 3.0, 'b': 2.0}])\n"
     ]
    }
   ],
   "source": [
    "def better_brute_force(lst_a: list or tuple or np.array\n",
    "                       ,lst_b:list or tuple or np.array\n",
    "                       ,y_hat:callable\n",
    "                       ,X:np.array\n",
    "                       ,Y:np.array\n",
    "                      )->tuple:\n",
    "\n",
    "    dict_mse = {}\n",
    "    for a in lst_a:\n",
    "        for b in lst_b:\n",
    "            Y_hat_a_b = y_hat(X,a=a,b=b)\n",
    "            mse = mse_function(Y_true=Y, Y_pred=Y_hat_a_b)\n",
    "            if mse in dict_mse.keys():\n",
    "                dict_mse[mse].append({\"a\":a,\"b\":b})\n",
    "            else:\n",
    "                dict_mse[mse] = [{\"a\":a,\"b\":b}]\n",
    "\n",
    "    best_mse = np.min(list(dict_mse.keys()))\n",
    "    \n",
    "    \n",
    "    return (best_mse,dict_mse[best_mse])\n",
    "\n",
    "print(better_brute_force(lst_a=lst_a\n",
    "                         ,lst_b=lst_b\n",
    "                         ,y_hat=y_hat\n",
    "                         ,X=X\n",
    "                         ,Y=Y\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60fb3b-1eda-4874-bf95-236e74a2c816",
   "metadata": {},
   "source": [
    "### methode \"steepest hill-climbing\" \n",
    "- methode \"escalade\"\n",
    "- EN: steepest hill-climbing method\n",
    "\n",
    "- l'idée s'est\n",
    "    - d'évaluer autour d'un point, un ensemble de directions;\n",
    "    - ensuite prendre la direction avec le meilleur résultat comme nouveau point;\n",
    "    - repeter ces étapes jusqu'à obtenir un maximum/minimum ou un plateau\n",
    "\n",
    "- NOTE: comme on evalue pas toutes les options, on peut potentiellement ne pas trouver le min/max global, mais seulement le min/max local(= pas une optimisation parfaite). Cependent, comme on fait moins de calculs, on met moins de temps à obtenir un résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da41884a-e012-44ee-92f7-8ae1b22b9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (cet algo peut être optimisé)\n",
    "\n",
    "def steepest_hill(X:np.array\n",
    "                  ,Y:np.array\n",
    "                  ,y_hat:callable = y_hat\n",
    "                  ,init_point:dict = {\"a\":4,\"b\":1}\n",
    "                  ,delta:dict = {\"a\":0.1,\"b\":0.1}\n",
    "                  ,MAX_COUNTER = 10_000\n",
    "                 )->list:\n",
    "    prev_point = init_point.copy()\n",
    "    \n",
    "    prev_point[\"mse\"] = mse_function(Y_true=Y, Y_pred=y_hat(x=X,a=init_point[\"a\"],b=init_point[\"b\"]))\n",
    "    best_points = []\n",
    "    COUNTER = 0\n",
    "    \n",
    "    while (prev_point not in best_points): \n",
    "        a_nexts = (prev_point[\"a\"] - delta[\"a\"], prev_point[\"a\"] + delta[\"a\"], prev_point[\"a\"])\n",
    "        b_nexts = (prev_point[\"b\"] - delta[\"b\"], prev_point[\"b\"] + delta[\"b\"], prev_point[\"b\"])\n",
    "        neighbours = [{\"a\":a, \"b\":b} for a in a_nexts for b in b_nexts][:-1]    \n",
    "        ## contruire toutes les combinaisons possibles de voisin, sans le point actuel \n",
    "                                                                                \n",
    "        MSE = []\n",
    "        for n in neighbours:\n",
    "            mse = mse_function(Y_true=Y, Y_pred=y_hat(x=X,a= n[\"a\"] , b = n[\"b\"]))\n",
    "            MSE.append(mse)\n",
    "        \n",
    "        best_point_pos = np.argmin(MSE)\n",
    "        best_point = neighbours[best_point_pos]\n",
    "        best_point[\"mse\"]=MSE[best_point_pos]\n",
    "        \n",
    "        best_points.append(prev_point)\n",
    "        \n",
    "        if prev_point[\"mse\"] > best_point[\"mse\"]:\n",
    "            prev_point = best_point\n",
    "            COUNTER +=1\n",
    "            if COUNTER >= MAX_COUNTER:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    #print(COUNTER)\n",
    "    return best_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bcae5db-0778-4fcf-973e-41feed90ea38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 4, 'b': 3.5, 'mse': 75.0124527476669},\n",
       " {'a': 3.9, 'b': 3.4, 'mse': 64.88165627631209},\n",
       " {'a': 3.8, 'b': 3.3, 'mse': 55.49138583687726},\n",
       " {'a': 3.6999999999999997, 'b': 3.1999999999999997, 'mse': 46.84164142936235},\n",
       " {'a': 3.5999999999999996, 'b': 3.0999999999999996, 'mse': 38.93242305376739},\n",
       " {'a': 3.4999999999999996, 'b': 2.9999999999999996, 'mse': 31.763730710092368},\n",
       " {'a': 3.3999999999999995, 'b': 2.8999999999999995, 'mse': 25.335564398337283},\n",
       " {'a': 3.2999999999999994, 'b': 2.7999999999999994, 'mse': 19.647924118502157},\n",
       " {'a': 3.1999999999999993, 'b': 2.6999999999999993, 'mse': 14.700809870586966},\n",
       " {'a': 3.099999999999999, 'b': 2.599999999999999, 'mse': 10.49422165459172},\n",
       " {'a': 2.999999999999999, 'b': 2.499999999999999, 'mse': 7.02815947051642},\n",
       " {'a': 2.899999999999999, 'b': 2.399999999999999, 'mse': 4.30262331836106},\n",
       " {'a': 2.799999999999999, 'b': 2.299999999999999, 'mse': 2.317613198125645},\n",
       " {'a': 2.699999999999999, 'b': 2.199999999999999, 'mse': 1.073129109810173},\n",
       " {'a': 2.5999999999999988, 'b': 2.0999999999999988, 'mse': 0.5691710534146442},\n",
       " {'a': 2.4999999999999987, 'b': 2.0999999999999988, 'mse': 0.560251477975108}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steepest_hill(X=X, Y=Y, y_hat=y_hat,init_point={\"a\":4,\"b\":3.5}) ## on arrive à un min LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f8a661-efcb-4534-8e46-826bd81ec5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 3.4, 'b': 2.3, 'mse': 4.232097491748378},\n",
       " {'a': 3.35, 'b': 2.25, 'mse': 3.157047983354276},\n",
       " {'a': 3.3000000000000003, 'b': 2.2, 'mse': 2.2671299829401597},\n",
       " {'a': 3.2500000000000004, 'b': 2.1500000000000004, 'mse': 1.562343490506026},\n",
       " {'a': 3.2000000000000006, 'b': 2.1000000000000005, 'mse': 1.042688506051878},\n",
       " {'a': 3.150000000000001, 'b': 2.0500000000000007, 'mse': 0.7081650295777128},\n",
       " {'a': 3.100000000000001, 'b': 2.000000000000001, 'mse': 0.5587730610835326},\n",
       " {'a': 3.050000000000001, 'b': 2.000000000000001, 'mse': 0.5518535584048253},\n",
       " {'a': 3.0000000000000013, 'b': 2.000000000000001, 'mse': 0.5499340557261181}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " steepest_hill(X=X, \n",
    "               Y=Y, \n",
    "               y_hat=y_hat,\n",
    "               init_point={\"a\":3.4,\"b\":2.3}\n",
    "               , delta={\"a\":0.05,\"b\":0.05}\n",
    "              ) ## on arrive à un min GLOBAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e338bda-95a6-49f7-909d-9a33ef2e8cd9",
   "metadata": {},
   "source": [
    "### [déscente de gradients](https://en.wikipedia.org/wiki/Gradient_descent)\n",
    "- EN: gradient descent\n",
    "- prérequis:\n",
    "    - dérivés & gradients de fonction\n",
    "        - la tangente/pente de la fonction \n",
    "    \n",
    "    - fonction convexe\n",
    "        - fonction qui a une dérivée de deuxième degrée qui est positif ou nul sur tout son domaine\n",
    "- on se déplace en fonction de la pente du gradient/derivée, plutot qu'avec un interval fixe\n",
    "\n",
    "Idée de l'algo:\n",
    "- On se met à la place de la machine\n",
    "- On est une personne aveugle et sourde dans une valée et on souhaite rejoindre le lac (ou une rivière)\n",
    "    - la machine est aveugle et sourde:\n",
    "        - on peut mesurer les chose que très localement; la machine doit calculer pour savoir, il n'y a pas d'autres possibilités\n",
    "- La fonction qui fait la valée c'est la \"fonction de perte/coût\"\n",
    "- À chaque point (ou nouveau déplacement) on peut sentir la pente (=calculer le gradient)\n",
    "- Dans une valée convexe, plus on s'éloigne du minimum, plus la pente est élevé (*). Et inversement: quand on est proche du minimum, la pente est plus douce.\n",
    "- Donc, quand une pente est élevée, il vaut mieux parcourir plus de distance avant de calculer la pente suivante.\n",
    "    - on peut décider si il faut avancer prudamment ou pas:\n",
    "        - ceci est déterminé par un facteur 'lambda' $\\lambda$ :\n",
    "            - la vitesse d'apprentissage (EN: learning rate)\n",
    "            - avec un $\\lambda$ élevé, pour un même gradient, on parcours une plus longue distance \n",
    "- Après un certain nombre d'étape (ou quand on ne distingue plus de différence significatifs) on est proche du minimum\n",
    "- À noter que quand on est au minimum (pour une fonction convexe), le gradient est éxactement égal à $0$\n",
    "\n",
    "(*) Ce n'est pas tout à fait exacte et en réalité la situation est est plus complexe que cela, mais cela ne change pas la nature de l'algo employé.\n",
    "\n",
    "\n",
    "En résumé:\n",
    "- avec:\n",
    "    - $C(a,b) = MSE(y,f(X,a,b)) = (\\frac{1}{N}\\sum_n^N (y_n - a - b x_n)^2)$\n",
    "    - gradient $\\vec{\\nabla} C(a,b) = \\frac{\\partial C(a,b)}{\\partial a} \\vec{1}_a + \\frac{\\partial C(a,b)}{\\partial b} \\vec{1}_b = \\begin{bmatrix}\n",
    "        \\frac{\\partial C(a,b)}{\\partial a}\\\\\n",
    "        \\frac{\\partial C(a,b)}{\\partial b}\\end{bmatrix}$\n",
    "        - $\\frac{\\partial C(a,b)}{\\partial a} = - \\frac{2}{N} \\sum_n (y_n - a - b x_n) = \\text{function}(a,b)$\n",
    "        - $\\frac{\\partial C(a,b)}{\\partial b} = - \\frac{2}{N} \\sum_n (y_n - a - b x_n)*x_n  = \\text{function}(a,b)$\n",
    "    <br><br>\n",
    "- les nouveaux candidats $\\hat{a}^{(m+1)},\\hat{b}^{(m+1)}$ sont calculé sur base des anciens et des dérivées partielles/gradient:\n",
    "    - $\\hat{a}^{(m+1)} = \\hat{a}^{(m)} - \\lambda \\frac{\\partial C(a,b)}{\\partial a}|_{(a=\\hat{a}^{(m)},b=\\hat{b}^{(m)})}$\n",
    "    - $\\hat{b}^{(m+1)} = \\hat{b}^{(m)} - \\lambda \\frac{\\partial C(a,b)}{\\partial b}|_{(a= \\hat{a}^{(m)},b= \\hat{b}^{(m)})} $\n",
    "    \n",
    "    - ou avec une notation matricielle:\n",
    "        -  $\\begin{bmatrix}\n",
    "        \\hat{a}^{(m+1)}\\\\\n",
    "        \\hat{b}^{(m+1)}\\end{bmatrix} = \\hat{B}^{(m+1)} =  \\hat{B}^{(m)} - \\lambda \\vec{\\nabla} C(\\hat{B}^{(m)})$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f90d98f-c9dc-4430-839a-bf1d1bf8aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_a(a,b,X,Y): ### pour régression linéaire simple\n",
    "    N = len(X)\n",
    "    res = -2/N * np.sum(Y - a - b*X)\n",
    "    return res\n",
    "\n",
    "def partial_b(a,b,X,Y): ### pour régression linéaire simple\n",
    "    N = len(X)\n",
    "    res = -2/N * np.sum((Y - a - b*X)*X)\n",
    "    return res\n",
    "gradient_vector = {\"a\":partial_a, \"b\":partial_b}\n",
    "\n",
    "\n",
    "def gradient_descent(X\n",
    "                     ,Y\n",
    "                     ,gradient_vector\n",
    "                     ,init_point={\"a\":3.4,\"b\":2.3}\n",
    "                     ,learning_rate=0.01\n",
    "                     ,epoch=100\n",
    "                     , y_hat=y_hat ## pour voir le mse\n",
    "                     , mse_function=mse_function ## pour voir le mse\n",
    "                    ):\n",
    "\n",
    "    \n",
    "    lst_points = [init_point]\n",
    "    prev_point = init_point\n",
    "    for e in range(epoch):\n",
    "        new_point = {}\n",
    "        new_point[\"a\"] = prev_point[\"a\"] - learning_rate* gradient_vector[\"a\"](a=prev_point[\"a\"]\n",
    "                                                                    ,b=prev_point[\"b\"]\n",
    "                                                                    ,X=X\n",
    "                                                                    ,Y=Y\n",
    "                                                                   )\n",
    "        new_point[\"b\"] = prev_point[\"b\"] - learning_rate* gradient_vector[\"b\"](a=prev_point[\"a\"]\n",
    "                                                                    ,b=prev_point[\"b\"]\n",
    "                                                                    ,X=X\n",
    "                                                                    ,Y=Y\n",
    "                                                                   )\n",
    "        \n",
    "        \n",
    "        new_point[\"mse\"] =mse_function(Y_true=Y, Y_pred=y_hat(x=X,a=new_point[\"a\"],b=new_point[\"b\"]))\n",
    "        lst_points.append(new_point)\n",
    "        prev_point = new_point\n",
    "        \n",
    "    \n",
    "\n",
    "    return lst_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0cc7637-1048-4c7f-ae03-a3fb13d9cf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 4, 'b': 3},\n",
       " {'a': 3.7600710587642685, 'b': 1.7601625056105978, 'mse': 0.8036682365979374},\n",
       " {'a': 3.7779065616733343, 'b': 1.8586852687825237, 'mse': 0.572882730315408},\n",
       " {'a': 3.7753082158574127, 'b': 1.851102483369906, 'mse': 0.5713701792078911},\n",
       " {'a': 3.7743315828479385, 'b': 1.851931416439231, 'mse': 0.5712988616771284},\n",
       " {'a': 3.773228094970567, 'b': 1.8520931381514703, 'mse': 0.5712367818537961},\n",
       " {'a': 3.7721363762059794, 'b': 1.8523074266528339, 'mse': 0.5711749386662507},\n",
       " {'a': 3.771045433961218, 'b': 1.8525172184012229, 'mse': 0.5711132750224664},\n",
       " {'a': 3.7699561372506927, 'b': 1.8527270378722933, 'mse': 0.5710517900476936},\n",
       " {'a': 3.76886841470403, 'b': 1.852936526842216, 'mse': 0.5709904832220212},\n",
       " {'a': 3.767782269508163, 'b': 1.8531457141869454, 'mse': 0.5709293540292585},\n",
       " {'a': 3.7666976989427012, 'b': 1.85335459809247, 'mse': 0.5708684019547245},\n",
       " {'a': 3.765614700759166, 'b': 1.8535631791771903, 'mse': 0.5708076264852296},\n",
       " {'a': 3.764533272675238, 'b': 1.8537714578659774, 'mse': 0.5707470271090713},\n",
       " {'a': 3.7634534124148478, 'b': 1.8539794345983578, 'mse': 0.5706866033160295},\n",
       " {'a': 3.762375117704992, 'b': 1.8541871098120104, 'mse': 0.5706263545973623},\n",
       " {'a': 3.761298386275982, 'b': 1.8543944839440754, 'mse': 0.570566280445802},\n",
       " {'a': 3.7602232158614175, 'b': 1.8546015574310517, 'mse': 0.5705063803555511},\n",
       " {'a': 3.7591496041981847, 'b': 1.8548083307088064, 'mse': 0.5704466538222768},\n",
       " {'a': 3.7580775490264506, 'b': 1.8550148042125738, 'mse': 0.5703871003431082},\n",
       " {'a': 3.757007048089658, 'b': 1.8552209783769578, 'mse': 0.5703277194166314},\n",
       " {'a': 3.7559380991345215, 'b': 1.855426853635932, 'mse': 0.5702685105428849},\n",
       " {'a': 3.7548706999110224, 'b': 1.8556324304228413, 'mse': 0.5702094732233559},\n",
       " {'a': 3.7538048481724045, 'b': 1.8558377091704015, 'mse': 0.5701506069609767},\n",
       " {'a': 3.752740541675168, 'b': 1.8560426903107017, 'mse': 0.570091911260119},\n",
       " {'a': 3.7516777781790664, 'b': 1.8562473742752044, 'mse': 0.5700333856265908},\n",
       " {'a': 3.7506165554471007, 'b': 1.8564517614947464, 'mse': 0.5699750295676322},\n",
       " {'a': 3.749556871245515, 'b': 1.8566558523995407, 'mse': 0.5699168425919109},\n",
       " {'a': 3.748498723343792, 'b': 1.8568596474191752, 'mse': 0.569858824209518},\n",
       " {'a': 3.7474421095146484, 'b': 1.857063146982616, 'mse': 0.5698009739319643},\n",
       " {'a': 3.746387027534029, 'b': 1.857266351518207, 'mse': 0.5697432912721762},\n",
       " {'a': 3.7453334751811043, 'b': 1.8574692614536714, 'mse': 0.5696857757444909},\n",
       " {'a': 3.744281450238263, 'b': 1.8576718772161118, 'mse': 0.5696284268646532},\n",
       " {'a': 3.7432309504911103, 'b': 1.8578741992320118, 'mse': 0.5695712441498104},\n",
       " {'a': 3.7421819737284605, 'b': 1.8580762279272371, 'mse': 0.5695142271185096},\n",
       " {'a': 3.7411345177423345, 'b': 1.8582779637270355, 'mse': 0.5694573752906925},\n",
       " {'a': 3.740088580327954, 'b': 1.8584794070560378, 'mse': 0.5694006881876916},\n",
       " {'a': 3.7390441592837376, 'b': 1.8586805583382604, 'mse': 0.5693441653322264},\n",
       " {'a': 3.738001252411294, 'b': 1.8588814179971045, 'mse': 0.5692878062483996},\n",
       " {'a': 3.7369598575154215, 'b': 1.8590819864553572, 'mse': 0.5692316104616925},\n",
       " {'a': 3.7359199724040986, 'b': 1.8592822641351925, 'mse': 0.5691755774989611},\n",
       " {'a': 3.7348815948884835, 'b': 1.8594822514581728, 'mse': 0.5691197068884327},\n",
       " {'a': 3.733844722782907, 'b': 1.8596819488452492, 'mse': 0.5690639981597014},\n",
       " {'a': 3.732809353904868, 'b': 1.8598813567167625, 'mse': 0.5690084508437241},\n",
       " {'a': 3.731775486075031, 'b': 1.860080475492444, 'mse': 0.5689530644728171},\n",
       " {'a': 3.7307431171172194, 'b': 1.8602793055914166, 'mse': 0.5688978385806515},\n",
       " {'a': 3.7297122448584106, 'b': 1.860477847432196, 'mse': 0.5688427727022494},\n",
       " {'a': 3.7286828671287333, 'b': 1.86067610143269, 'mse': 0.5687878663739806},\n",
       " {'a': 3.727654981761462, 'b': 1.8608740680102014, 'mse': 0.568733119133558},\n",
       " {'a': 3.7266285865930127, 'b': 1.8610717475814278, 'mse': 0.5686785305200337},\n",
       " {'a': 3.7256036794629375, 'b': 1.8612691405624633, 'mse': 0.5686241000737958},\n",
       " {'a': 3.724580258213921, 'b': 1.8614662473687973, 'mse': 0.5685698273365639},\n",
       " {'a': 3.723558320691775, 'b': 1.8616630684153181, 'mse': 0.5685157118513856},\n",
       " {'a': 3.722537864745435, 'b': 1.8618596041163122, 'mse': 0.5684617531626324},\n",
       " {'a': 3.7215188882269543, 'b': 1.8620558548854653, 'mse': 0.5684079508159954},\n",
       " {'a': 3.7205013889915013, 'b': 1.8622518211358634, 'mse': 0.568354304358483},\n",
       " {'a': 3.719485364897353, 'b': 1.8624475032799939, 'mse': 0.5683008133384155},\n",
       " {'a': 3.7184708138058915, 'b': 1.8626429017297452, 'mse': 0.5682474773054224},\n",
       " {'a': 3.7174577335816, 'b': 1.8628380168964103, 'mse': 0.5681942958104372},\n",
       " {'a': 3.7164461220920573, 'b': 1.8630328491906842, 'mse': 0.5681412684056956},\n",
       " {'a': 3.7154359772079335, 'b': 1.8632273990226678, 'mse': 0.5680883946447299},\n",
       " {'a': 3.7144272968029863, 'b': 1.863421666801866, 'mse': 0.5680356740823667},\n",
       " {'a': 3.7134200787540554, 'b': 1.8636156529371917, 'mse': 0.5679831062747218},\n",
       " {'a': 3.712414320941059, 'b': 1.8638093578369637, 'mse': 0.5679306907791976},\n",
       " {'a': 3.7114100212469885, 'b': 1.8640027819089091, 'mse': 0.5678784271544784},\n",
       " {'a': 3.710407177557905, 'b': 1.8641959255601648, 'mse': 0.567826314960528},\n",
       " {'a': 3.709405787762934, 'b': 1.8643887891972761, 'mse': 0.5677743537585844},\n",
       " {'a': 3.708405849754261, 'b': 1.8645813732261993, 'mse': 0.567722543111157},\n",
       " {'a': 3.707407361427129, 'b': 1.8647736780523032, 'mse': 0.5676708825820233},\n",
       " {'a': 3.70641032067983, 'b': 1.8649657040803673, 'mse': 0.5676193717362241},\n",
       " {'a': 3.705414725413704, 'b': 1.8651574517145855, 'mse': 0.5675680101400611},\n",
       " {'a': 3.7044205735331346, 'b': 1.8653489213585648, 'mse': 0.5675167973610922},\n",
       " {'a': 3.703427862945542, 'b': 1.8655401134153275, 'mse': 0.5674657329681281},\n",
       " {'a': 3.7024365915613813, 'b': 1.865731028287312, 'mse': 0.5674148165312293},\n",
       " {'a': 3.701446757294136, 'b': 1.865921666376373, 'mse': 0.5673640476217018},\n",
       " {'a': 3.700458358060316, 'b': 1.866112028083782, 'mse': 0.5673134258120938},\n",
       " {'a': 3.6994713917794497, 'b': 1.8663021138102291, 'mse': 0.5672629506761919},\n",
       " {'a': 3.6984858563740834, 'b': 1.8664919239558242, 'mse': 0.5672126217890178},\n",
       " {'a': 3.697501749769775, 'b': 1.8666814589200962, 'mse': 0.5671624387268244},\n",
       " {'a': 3.696519069895089, 'b': 1.866870719101995, 'mse': 0.5671124010670922},\n",
       " {'a': 3.695537814681594, 'b': 1.8670597048998927, 'mse': 0.5670625083885265},\n",
       " {'a': 3.6945579820638565, 'b': 1.8672484167115828, 'mse': 0.5670127602710526},\n",
       " {'a': 3.6935795699794385, 'b': 1.8674368549342832, 'mse': 0.5669631562958136},\n",
       " {'a': 3.6926025763688908, 'b': 1.867625019964635, 'mse': 0.5669136960451656},\n",
       " {'a': 3.691626999175751, 'b': 1.8678129121987046, 'mse': 0.5668643791026752},\n",
       " {'a': 3.690652836346537, 'b': 1.8680005320319846, 'mse': 0.5668152050531156},\n",
       " {'a': 3.689680085830745, 'b': 1.8681878798593938, 'mse': 0.5667661734824625},\n",
       " {'a': 3.688708745580843, 'b': 1.8683749560752785, 'mse': 0.5667172839778923},\n",
       " {'a': 3.687738813552268, 'b': 1.868561761073413, 'mse': 0.5666685361277765},\n",
       " {'a': 3.686770287703421, 'b': 1.8687482952470014, 'mse': 0.5666199295216798},\n",
       " {'a': 3.6858031659956634, 'b': 1.8689345589886777, 'mse': 0.566571463750356},\n",
       " {'a': 3.6848374463933107, 'b': 1.8691205526905055, 'mse': 0.5665231384057446},\n",
       " {'a': 3.683873126863631, 'b': 1.8693062767439814, 'mse': 0.5664749530809676},\n",
       " {'a': 3.6829102053768383, 'b': 1.869491731540034, 'mse': 0.5664269073703255},\n",
       " {'a': 3.6819486799060908, 'b': 1.8696769174690244, 'mse': 0.5663790008692949},\n",
       " {'a': 3.680988548427484, 'b': 1.8698618349207492, 'mse': 0.5663312331745242},\n",
       " {'a': 3.680029808920048, 'b': 1.8700464842844384, 'mse': 0.56628360388383},\n",
       " {'a': 3.679072459365743, 'b': 1.8702308659487588, 'mse': 0.5662361125961951},\n",
       " {'a': 3.6781164977494543, 'b': 1.8704149803018129, 'mse': 0.5661887589117638},\n",
       " {'a': 3.677161922058989, 'b': 1.8705988277311414, 'mse': 0.5661415424318387},\n",
       " {'a': 3.676208730285072, 'b': 1.8707824086237224, 'mse': 0.5660944627588779}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X=X,Y=Y,gradient_vector=gradient_vector,init_point={\"a\":4,\"b\":3},learning_rate=0.02,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f648b5-f821-419b-b066-689eb73a502d",
   "metadata": {},
   "source": [
    "### [solution analytique pour régression linéaire simple](https://en.wikipedia.org/wiki/Ordinary_least_squares)\n",
    "- EN: analytical solution\n",
    "- comme ce problème est simple et très bien connu dans les mathématiques/statistiques, il existe un calcul qui permet d'obternir directement les paramètres optimaux:\n",
    "    - pour la régression linéaire simple (avec comme critère les moindres carrés ordinaire):\n",
    "        - $\\hat{b} = \\frac{\\sum_i (x_n - \\bar{x}) (y_n - \\bar{y})}{\\sum_n (x_n - \\bar{x})^2}$\n",
    "        - $\\hat{a} = \\bar{y} - \\hat{b} \\bar{x}$\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e9c055-3e7a-40bd-9165-8a1d16a044e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 3.0196846362599974, 'b': 1.9972263021612138}\n"
     ]
    }
   ],
   "source": [
    "### solution analytique \n",
    "x_moy = np.mean(X)\n",
    "y_moy = np.mean(Y)\n",
    "\n",
    "b_hat =  np.sum((X-x_moy)*(Y-y_moy))/np.sum((X-x_moy)*(X-x_moy))\n",
    "a_hat =  y_moy - b_hat*x_moy\n",
    "print({'a':a_hat,'b':b_hat})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32005d-267c-4e04-a66a-ccc194e226ae",
   "metadata": {},
   "source": [
    "## Genéralisation: regression linéaire multiple\n",
    "- $\\hat{y} = f(X) = a + b_1 x_1 + b_2 x_2 + ... + b_K x_K = a + \\sum_{k=1}^K b_k x_k $\n",
    "- $\\hat{y} = f(X) = b_0 1 + b_1 x_1 + b_2 x_2 + ... + b_K x_K = \\sum_{k=0}^K b_k x_k \\;$ avec $x_0 = 1$\n",
    "- le template de la regression depends de plus de variables, mais la dépendence entre ces variables est toujours linéaire\n",
    "- les données sont les tuples $\\{(y_n, x_{n,1}, x_{n,2}, ... , x_{n,K})\\}$\n",
    "\n",
    "- La seule différence avec le modèle linéaire simple, c'est qu'on a plus de variable \"explicatives\"/\"indépendentes\".\n",
    "- Les techniques d'optimisation vu plus haut (force brut, steepest hill, gradient, analytique), s'applique de manière similaire à ce modèle-ci.\n",
    "\n",
    "### Solution analytique : [methode des moindre carrés ordinaire](https://en.wikipedia.org/wiki/Ordinary_least_squares)\n",
    "- $X = \\begin{bmatrix}\n",
    "    1 &x_{1,1} & ... & x_{1,K}\\\\\n",
    "    ... & ... & ... & ... \\\\\n",
    "    1 & x_{N,1} & ... & x_{N,K}\n",
    "\\end{bmatrix}$ , $y = \\begin{bmatrix}\n",
    "    y_{1}\\\\\n",
    "    ...  \\\\\n",
    "    y_{N}\n",
    "\\end{bmatrix}$, $\\hat{b} = \\begin{bmatrix}\n",
    "    b_{0}\\\\\n",
    "    ...  \\\\\n",
    "    b_{K}\n",
    "\\end{bmatrix}$\n",
    "- $\\hat{b} = (X^TX)^{-1} X^Ty$\n",
    "\n",
    "[comment]: <> (- $[b]_{[K+1,1]} = [(X^T X)^{-1}]_{[K+1,K+1]} [X^T]_{[K+1,N]}[y]_{[N,1]}  $)\n",
    "\n",
    "### Généralisation solution analytique pour modèle linéaire:\n",
    "Comme c'est un modèle très simple et bien connu, il existe un/plusieurs calculs (algèbre linéaire) pour obtenir les meilleurs paramètres de ce modèle linéaire:\n",
    "- [methode des moindre carrés pondérés](https://en.wikipedia.org/wiki/Weighted_least_squares)\n",
    "- [methode des moindre carrés généralisés](https://en.wikipedia.org/wiki/Generalized_least_squares)\n",
    "\n",
    "\n",
    "\n",
    "### Régression polynomiale\n",
    "- $\\hat{y} = f(x) = b_0 + b_1 x_1 + b_2 x^2 + ... +  b_K x^K = \\sum_{k=0}^K b_k x^k $\n",
    "- traduit en regression multiple:\n",
    "    - $x_k = x^k = x * x * ... *x$\n",
    "\n",
    "\n",
    "### Generalisation pour modèle non-polynomial est inconnu: \n",
    "Un calcul général pour les paramètres optimaux n'existe pas pour un modèle arbitraire (non-linéaire), et on est donc souvent amené à utiliser les algo altérnatifs pour ceux-ci, comme: \n",
    "- grid search\n",
    "- \"steepest hill-climbing\"\n",
    "- descente de gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d8888-d442-4626-a990-8999a3cfb586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1762b5f-04ed-4443-a848-935c04edf1cb",
   "metadata": {},
   "source": [
    "## P-values d'une regression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b7bf03-154f-480e-b940-f0777d1ee77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>coef</th>\n",
       "      <th>se</th>\n",
       "      <th>T</th>\n",
       "      <th>pval</th>\n",
       "      <th>r2</th>\n",
       "      <th>adj_r2</th>\n",
       "      <th>CI[2.5%]</th>\n",
       "      <th>CI[97.5%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>3.019685</td>\n",
       "      <td>0.038253</td>\n",
       "      <td>78.939973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876451</td>\n",
       "      <td>0.876439</td>\n",
       "      <td>2.944701</td>\n",
       "      <td>3.094668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1</td>\n",
       "      <td>1.997226</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>266.318695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876451</td>\n",
       "      <td>0.876439</td>\n",
       "      <td>1.982526</td>\n",
       "      <td>2.011927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       names      coef        se           T  pval        r2    adj_r2  \\\n",
       "0  Intercept  3.019685  0.038253   78.939973   0.0  0.876451  0.876439   \n",
       "1         x1  1.997226  0.007499  266.318695   0.0  0.876451  0.876439   \n",
       "\n",
       "   CI[2.5%]  CI[97.5%]  \n",
       "0  2.944701   3.094668  \n",
       "1  1.982526   2.011927  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.linear_regression(X=X, y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2d7a1-b80e-489e-9330-dbc19af5fbc0",
   "metadata": {},
   "source": [
    "## [régression logistique simple (binaire)](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "\n",
    "- pour faire de la classification !\n",
    "    - par contre, au lieu de prédire (simplement) la classe, on prédit la probabilité pour chaque classe\n",
    "        - c'est pour cela qu'il a quand même \"regression\" dans le nom\n",
    "\n",
    "- Comparaison avec la régression linéaire:\n",
    "    - Points communs:\n",
    "        1. la séparation des classe est définie par un (hyper)plan ou droite = modèle linéaire\n",
    "        2. il y a des paramètre d'une fonction linéaire à trouver\n",
    "            - $a ?,b? : f(x) \\sim a + bx$ \n",
    "    - Points différents:\n",
    "        1. c'est pour la classification\n",
    "        2. cela prédit une 'probabilité' $P(y)$\n",
    "            - $P(y) = F_y(X)$ \n",
    "        4. le modèle complet (binaire) est défini par le modèle logistique:\n",
    "            - $P(y=1) = F(X) = \\frac{1}{1+e^{-(a + bx)}}$\n",
    "            - forlulation altérnatives (mathématiquement identiques):\n",
    "                - $P(y=0) = \\frac{e^{\\frac{-(a+bx)}{2}}}{e^{\\frac{-(a+bx)}{2}}+e^{\\frac{+(a+bx)}{2}}} \n",
    "                =\\frac{e^{-(a'+b'x)}}{e^{-(a'+b'x)}+e^{+(a'+b'x)}}$\n",
    "                - $P(y=1) = \\frac{e^{\\frac{+(a+bx)}{2}}}{e^{\\frac{-(a+bx)}{2}}+e^{\\frac{+(a+bx)}{2}}}\n",
    "                =\\frac{e^{+(a'+b'x)}}{e^{-(a'+b'x)}+e^{+(a'+b'x)}}$\n",
    "    - on peut reformuler la regression logistique pour en faire une régression linéaire:\n",
    "        - $\\ln{(\\frac{P(y)}{1-P(y)} )} = a+bx$\n",
    "        - $\\ln{(\\frac{P(y=1)}{P(y=0)})} = a+bx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f59522a-a6ea-4ea3-ae8e-8592de25ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_logistic = 100 \n",
    "\n",
    "X_a = np.random.normal(0,1,(N_logistic)) + 7\n",
    "X_b = 1.1*np.random.normal(0,1,(N_logistic)) + 3\n",
    "\n",
    "Cat_a = np.ones(N_logistic,dtype=int)\n",
    "Cat_b = np.zeros(N_logistic,dtype=int)\n",
    "\n",
    "X_ab = np.concatenate([X_a,X_b])\n",
    "Cat_ab = np.concatenate([Cat_a,Cat_b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fa56bd1-e624-4a77-97e3-026d704de2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>coef</th>\n",
       "      <th>se</th>\n",
       "      <th>z</th>\n",
       "      <th>pval</th>\n",
       "      <th>CI[2.5%]</th>\n",
       "      <th>CI[97.5%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-23.909323</td>\n",
       "      <td>6.143998</td>\n",
       "      <td>-3.891492</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-35.951338</td>\n",
       "      <td>-11.867308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1</td>\n",
       "      <td>4.594693</td>\n",
       "      <td>1.189399</td>\n",
       "      <td>3.863036</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>2.263513</td>\n",
       "      <td>6.925873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       names       coef        se         z      pval   CI[2.5%]  CI[97.5%]\n",
       "0  Intercept -23.909323  6.143998 -3.891492  0.000100 -35.951338 -11.867308\n",
       "1         x1   4.594693  1.189399  3.863036  0.000112   2.263513   6.925873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pg.logistic_regression(X=X_ab, y=Cat_ab)\n",
    "display(res)\n",
    "\n",
    "def sigmoid(X,intercept=0,coef=0):\n",
    "    exponent =  intercept + X*coef  ## a+bx\n",
    "    return 1/(1+np.exp(-exponent))  ## 1/(1+ exp[-(a+bx)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8cbc4-9584-4de8-995e-1a535ab5c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_theorique,sigmoid(X=x_theorique,intercept=res.at[0,'coef'],coef=res.at[1,'coef']), label='logistic_regression',c='red')\n",
    "plt.scatter(x=X_a, y=Cat_a,c='darkblue',label='a')\n",
    "plt.scatter(x=X_b, y=Cat_b,c='orange',label='b')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9580a2-4dfe-4f63-8243-82944c25c925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "959262d0-3416-4036-8d4c-2f8794d385f0",
   "metadata": {},
   "source": [
    "## régression logistique multiple (binaire)\n",
    "- comme pour la régression linéaire, on peut avoir plusieurs variables explicatives (features)\n",
    "    - $P(y=1) = F(X) = \\frac{1}{1+e^{-(a + \\sum_{k=1}^K b_k x_k)}}$\n",
    "    - $\\ln{(\\frac{P(y)}{1-P(y)} )} = a + \\sum_{k=1}^K b_k x_k$\n",
    "\n",
    "## [regression logistique multinomiale](https://en.wikipedia.org/wiki/Multinomial_logistic_regression)\n",
    "- régression logistique multi-classes, régression softmax\n",
    "- EN: multinomial logistic regression, multi-class logistic regression, softmax regression\n",
    "\n",
    "- Au lieu d'avoir une classification binaire $\\{0,1\\}$, on a une classification multinomiale/multi-classes $\\{1,2,...,m,...,M\\}$\n",
    "    - pour généraliser le modèle, il faut prendre comme hypothèse que le probabilité est proportionnel à une fontion linéaire dans une exponentiel\n",
    "        - $\\forall m: P(y=m) \\sim e^{-(a_m + \\sum_{k=1}^K b_{k,m} x_k)}$\n",
    "        - note: les paramètres $a_m,b_{k,m}$ peuvent être différents pour chaque $m$. Donc, pour chaque $m$ on a une fonction linéaire différente !\n",
    "    - altérnativement: le logarithme de la probabilité est proportionnel à une fonction linéaire\n",
    "        - $\\forall m: \\ln (P(y=m)) \\sim -(a_m + \\sum_{k=1}^K b_{k,m} x_k)$\n",
    "\n",
    "    - on sait que la somme des proba vaut $1$: on peut donc déterminer un facteur de normalisation $Z$\n",
    "        - $Z = \\sum_{m=1}^{M} e^{-(a_m + \\sum_{k=1}^K b_{k,m} x_k)}$\n",
    "        - $\\forall m : P(y=m) = \\frac{1}{Z}e^{-(a_m + \\sum_{k=1}^K b_{k,m} x_k)}$\n",
    "\n",
    "        - la fonction avec les ratio d'exponentielles $\\frac{e^{-x_i}}{\\sum e^{-x_i}}$ s'appelle la [\"softmax\"](https://en.wikipedia.org/wiki/Softmax_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7241e-ad96-4e50-82a6-610a59c58a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
